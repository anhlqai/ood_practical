{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "w71s1dF4DZO2",
        "b7sewRnvqAJd",
        "3vxI5FUKURaw",
        "OH3y28JOHGtv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# load drive and librabies\n"
      ],
      "metadata": {
        "id": "vDvMejLiD8fI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35YUDX-JQ8iu",
        "outputId": "db1b0726-d40f-4dd3-b80e-2e82aa5a4ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyod"
      ],
      "metadata": {
        "id": "krGGnstmuJz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HCMqLeMugv2",
        "outputId": "3c0a97cf-5510-4c8f-a5be-d01aae4bb215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/19rDR7CIzlqpEM2y_t3vRDkf0-aHH8tdE/ood_practical/RTL/CIFAR/CIFAR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.transforms as trn\n",
        "import torchvision.datasets as dset\n",
        "import torch.nn.functional as F\n",
        "from models.wrn import WideResNet\n",
        "from skimage.filters import gaussian as gblur\n",
        "from PIL import Image as PILImage\n",
        "from PIL import ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "-Degb3hawm8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR10Dataset"
      ],
      "metadata": {
        "id": "R86HMxNbEHjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Chuẩn bị dữ liệu\n",
        "class CIFAR10Dataset(Dataset):\n",
        "    def __init__(self, data_files, transform=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "        for file in data_files:\n",
        "            with open(file, 'rb') as f:\n",
        "                batch = pickle.load(f, encoding='bytes')\n",
        "                self.data.append(batch[b'data'])\n",
        "                self.labels.extend(batch[b'labels'])\n",
        "\n",
        "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32).astype(np.uint8)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.data[idx].transpose(1, 2, 0)\n",
        "        img = Image.fromarray(img)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "# Đường dẫn đến các file batch\n",
        "data_dir = \"/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/data/cifar10py/cifar-10-batches-py\"\n",
        "\n",
        "train_files = [\n",
        "    f\"{data_dir}/data_batch_1\",\n",
        "    f\"{data_dir}/data_batch_2\",\n",
        "    f\"{data_dir}/data_batch_3\",\n",
        "    f\"{data_dir}/data_batch_4\",\n",
        "    f\"{data_dir}/data_batch_5\"\n",
        "]\n",
        "test_file = f\"{data_dir}/test_batch\"\n",
        "\n",
        "# 2. Transforms cho hình ảnh\n",
        "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
        "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
        "\n",
        "transform = trn.Compose([\n",
        "    trn.Resize(224),\n",
        "    trn.ToTensor(),\n",
        "    trn.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "# Tạo dataset và dataloader\n",
        "train_dataset = CIFAR10Dataset(train_files, transform=transform)\n",
        "test_dataset = CIFAR10Dataset([test_file], transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "Upp6Co_Uwk7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vits16 = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
        "vits16.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVYvi6TycAdg",
        "outputId": "ff3e5683-edcf-4141-b4bd-d5bf676d155a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n",
            "100%|██████████| 82.7M/82.7M [00:00<00:00, 89.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-11): 12 x Block(\n",
              "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (attn): Attention(\n",
              "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (drop_path): Identity()\n",
              "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (mlp): Mlp(\n",
              "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "        (drop): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "  (head): Identity()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# extract features"
      ],
      "metadata": {
        "id": "OyjXHvRDzwIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(model, loader, name):\n",
        "  features = []\n",
        "  vits16.eval()\n",
        "\n",
        "  with torch.no_grad():  # Disable gradient calculation during inference\n",
        "    for batch_idx, (data, target) in enumerate(tqdm(loader, desc=\"Processing\")):  # Use tqdm for progress bar\n",
        "        # Chuyển dữ liệu sang thiết bị (CPU or GPU)\n",
        "        data = data.to(device)  # Replace 'device' with your device (e.g., 'cuda' or 'cpu')\n",
        "        # Tính toán output của mô hình\n",
        "        output = vits16(data)\n",
        "        # Lưu output vào list\n",
        "        features.append(output)\n",
        "\n",
        "  features = torch.cat(features, dim=0)\n",
        "  torch.save(features, f'/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/features224/{name}.pt')"
      ],
      "metadata": {
        "id": "3H4mfapsrR4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_features(vits16, train_loader, 'train_features')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH7DE91ssvYa",
        "outputId": "2789889a-cf8d-4446-c595-2f86d97fa16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 782/782 [03:01<00:00,  4.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_features(vits16, test_loader, 'test_features')"
      ],
      "metadata": {
        "id": "WJnGZmMEsGNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54236077-2bc6-492e-af47-378985db6658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 157/157 [00:37<00:00,  4.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## extract ood features"
      ],
      "metadata": {
        "id": "w71s1dF4DZO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /////////////// Textures ///////////////\n",
        "ood_data = dset.ImageFolder(root=\"./data/dtd/images/\",\n",
        "                        transform=trn.Compose([trn.Resize(224), trn.CenterCrop(32),\n",
        "                                               trn.ToTensor(), trn.Normalize(mean, std)]))\n",
        "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
        "                                     num_workers=0, pin_memory=False)\n",
        "ood_loader.name = \"Textures\"\n",
        "print('\\n\\nTexture Detection')\n",
        "\n",
        "extract_features(vits16, ood_loader, 'texture_features')"
      ],
      "metadata": {
        "id": "GwI28jJqs4kL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61fc296a-bb53-4a12-9fdc-b51ca0933e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Texture Detection\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 89/89 [47:16<00:00, 31.87s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /////////////// Places365 ///////////////\n",
        "ood_data = dset.ImageFolder(root=\"./data/Places365/\",\n",
        "                            transform=trn.Compose([trn.Resize(224), trn.CenterCrop(32),\n",
        "                                                   trn.ToTensor(), trn.Normalize(mean, std)]))\n",
        "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
        "                                         num_workers=0, pin_memory=False)\n",
        "ood_loader.name = \"Places365\"\n",
        "print('\\n\\nPlaces365 Detection')\n",
        "places365_features = extract_features(vits16, ood_loader, 'places365_features')"
      ],
      "metadata": {
        "id": "hUw5z9hIvpKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a30928-f628-46db-c43f-655a00d424e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Places365 Detection\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 303/303 [13:34<00:00,  2.69s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# /////////////// LSUN-C ///////////////\n",
        "ood_data = dset.ImageFolder(root=\"./data/LSUN/\",\n",
        "                            transform=trn.Compose([trn.Resize(224), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
        "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
        "                                         num_workers=0, pin_memory=False)\n",
        "ood_loader.name = \"LSUN-C\"\n",
        "print('\\n\\nLSUN_C Detection')\n",
        "extract_features(vits16, ood_loader, 'lsun-c_features')"
      ],
      "metadata": {
        "id": "8abh5i-LvyKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /////////////// LSUN-R ///////////////\n",
        "ood_data = dset.ImageFolder(root=\"./data/LSUN_resize/\",\n",
        "                            transform=trn.Compose([trn.Resize(224), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
        "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
        "                                         num_workers=0, pin_memory=False)\n",
        "ood_loader.name = \"LSUN-R\"\n",
        "print('\\n\\nLSUN_Resize Detection')\n",
        "extract_features(vits16, ood_loader, 'lsun-r_features')"
      ],
      "metadata": {
        "id": "umknabwOyIXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# /////////////// iSUN ///////////////\n",
        "ood_data = dset.ImageFolder(root=\"./data/iSUN/\",\n",
        "                            transform=trn.Compose([trn.Resize(224), trn.ToTensor(), trn.Normalize(mean, std)]))\n",
        "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
        "                                         num_workers=0, pin_memory=False)\n",
        "ood_loader.name = \"iSUN\"\n",
        "print('\\n\\niSUN Detection')\n",
        "extract_features(vits16, ood_loader, 'isun_features')"
      ],
      "metadata": {
        "id": "bbSrnG4ryVss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVHN\n"
      ],
      "metadata": {
        "id": "b7sewRnvqAJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR"
      ],
      "metadata": {
        "id": "ZsZRMNTSzdfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class SVHN(data.Dataset):\n",
        "    url = \"\"\n",
        "    filename = \"\"\n",
        "    file_md5 = \"\"\n",
        "\n",
        "    split_list = {\n",
        "        'train': [\"http://ufldl.stanford.edu/housenumbers/train_32x32.mat\",\n",
        "                  \"train_32x32.mat\", \"e26dedcc434d2e4c54c9b2d4a06d8373\"],\n",
        "        'test': [\"http://ufldl.stanford.edu/housenumbers/test_32x32.mat\",\n",
        "                 \"test_32x32.mat\", \"eb5a983be6a315427106f1b164d9cef3\"],\n",
        "        'extra': [\"http://ufldl.stanford.edu/housenumbers/extra_32x32.mat\",\n",
        "                  \"extra_32x32.mat\", \"a93ce644f1a588dc4d68dda5feec44a7\"],\n",
        "        'train_and_extra': [\n",
        "                [\"http://ufldl.stanford.edu/housenumbers/train_32x32.mat\",\n",
        "                 \"train_32x32.mat\", \"e26dedcc434d2e4c54c9b2d4a06d8373\"],\n",
        "                [\"http://ufldl.stanford.edu/housenumbers/extra_32x32.mat\",\n",
        "                 \"extra_32x32.mat\", \"a93ce644f1a588dc4d68dda5feec44a7\"]]}\n",
        "\n",
        "    def __init__(self, root, split='train',\n",
        "                 transform=None, target_transform=None, download=False):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.split = split  # training set or test set or extra set\n",
        "\n",
        "        if self.split not in self.split_list:\n",
        "            raise ValueError('Wrong split entered! Please use split=\"train\" '\n",
        "                             'or split=\"extra\" or split=\"test\" '\n",
        "                             'or split=\"train_and_extra\" ')\n",
        "\n",
        "        if self.split == \"train_and_extra\":\n",
        "            self.url = self.split_list[split][0][0]\n",
        "            self.filename = self.split_list[split][0][1]\n",
        "            self.file_md5 = self.split_list[split][0][2]\n",
        "        else:\n",
        "            self.url = self.split_list[split][0]\n",
        "            self.filename = self.split_list[split][1]\n",
        "            self.file_md5 = self.split_list[split][2]\n",
        "\n",
        "        # import here rather than at top of file because this is\n",
        "        # an optional dependency for torchvision\n",
        "        import scipy.io as sio\n",
        "\n",
        "        # reading(loading) mat file as array\n",
        "        loaded_mat = sio.loadmat(os.path.join(root, self.filename))\n",
        "\n",
        "        if self.split == \"test\":\n",
        "            self.data = loaded_mat['X']\n",
        "            self.targets = loaded_mat['y']\n",
        "            # Note label 10 == 0 so modulo operator required\n",
        "            self.targets = (self.targets % 10).squeeze()    # convert to zero-based indexing\n",
        "            self.data = np.transpose(self.data, (3, 2, 0, 1))\n",
        "        else:\n",
        "            self.data = loaded_mat['X']\n",
        "            self.targets = loaded_mat['y']\n",
        "\n",
        "            if self.split == \"train_and_extra\":\n",
        "                extra_filename = self.split_list[split][1][1]\n",
        "                loaded_mat = sio.loadmat(os.path.join(root, extra_filename))\n",
        "                self.data = np.concatenate([self.data,\n",
        "                                                  loaded_mat['X']], axis=3)\n",
        "                self.targets = np.vstack((self.targets,\n",
        "                                               loaded_mat['y']))\n",
        "            # Note label 10 == 0 so modulo operator required\n",
        "            self.targets = (self.targets % 10).squeeze()    # convert to zero-based indexing\n",
        "            self.data = np.transpose(self.data, (3, 2, 0, 1))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.split == \"test\":\n",
        "            img, target = self.data[index], self.targets[index]\n",
        "        else:\n",
        "            img, target = self.data[index], self.targets[index]\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(np.transpose(img, (1, 2, 0)))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.split == \"test\":\n",
        "            return len(self.data)\n",
        "        else:\n",
        "            return len(self.data)\n",
        "\n",
        "    def _check_integrity(self):\n",
        "        root = self.root\n",
        "        if self.split == \"train_and_extra\":\n",
        "            md5 = self.split_list[self.split][0][2]\n",
        "            fpath = os.path.join(root, self.filename)\n",
        "            train_integrity = check_integrity(fpath, md5)\n",
        "            extra_filename = self.split_list[self.split][1][1]\n",
        "            md5 = self.split_list[self.split][1][2]\n",
        "            fpath = os.path.join(root, extra_filename)\n",
        "            return check_integrity(fpath, md5) and train_integrity\n",
        "        else:\n",
        "            md5 = self.split_list[self.split][2]\n",
        "            fpath = os.path.join(root, self.filename)\n",
        "            return check_integrity(fpath, md5)\n",
        "\n",
        "    def download(self):\n",
        "        if self.split == \"train_and_extra\":\n",
        "            md5 = self.split_list[self.split][0][2]\n",
        "            download_url(self.url, self.root, self.filename, md5)\n",
        "            extra_filename = self.split_list[self.split][1][1]\n",
        "            md5 = self.split_list[self.split][1][2]\n",
        "            download_url(self.url, self.root, extra_filename, md5)\n",
        "        else:\n",
        "            md5 = self.split_list[self.split][2]\n",
        "            download_url(self.url, self.root, self.filename, md5)\n"
      ],
      "metadata": {
        "id": "BiHNPWdyqE6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # /////////////// SVHN /////////////// # cropped and no sampling of the test set\n",
        "# ood_data = SVHN(root='./CIFAR/data/SVHN/', split=\"test\",\n",
        "#                      transform=trn.Compose(\n",
        "#                          [trn.Resize(224),\n",
        "#                          trn.ToTensor(), trn.Normalize(mean, std)]), download=False)\n",
        "# ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=64, shuffle=True,\n",
        "#                                          num_workers=0, pin_memory=False)\n",
        "# ood_loader.name = \"SVHN\"\n",
        "# print('\\n\\nSVHN Detection')\n",
        "# extract_features(vits16, ood_loader, 'svhn_features')"
      ],
      "metadata": {
        "id": "wH8R1dfqvfgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load features"
      ],
      "metadata": {
        "id": "TeT8m42s0bYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = torch.load('/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/features224/train_features.pt').cpu().numpy()\n",
        "in_features = torch.load('/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/features224/test_features.pt').cpu().numpy()\n",
        "\n",
        "texture_features = torch.load('/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/features224/texture_features.pt').cpu().numpy()\n",
        "places365_features = torch.load('/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/features224/places365_features.pt').cpu().numpy()\n",
        "lsun_c_features = torch.load('/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/features224/lsun-c_features.pt').cpu().numpy()\n",
        "lsun_r_features = torch.load('/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/features224/lsun-r_features.pt').cpu().numpy()\n",
        "isun_features = torch.load('/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/features224/isun_features.pt').cpu().numpy()\n",
        "# svhn_features = torch.load('/content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR/CIFAR/features224/svhn_features.pt')"
      ],
      "metadata": {
        "id": "_OZnpIflz-qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape, test_features.shape, texture_features.shape, places365_features.shape, lsun_c_features.shape, lsun_r_features.shape, isun_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hrpLG5RHR21",
        "outputId": "462f7469-8f86-483b-8014-eb41056c59c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 384),\n",
              " (10000, 384),\n",
              " (5640, 384),\n",
              " (19367, 384),\n",
              " (10000, 384),\n",
              " (10000, 384),\n",
              " (8925, 384))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "3vxI5FUKURaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import ElasticNet, LinearRegression\n",
        "\n",
        "class RTL_OOD(object):\n",
        "\n",
        "    def __init__(self, reduce=\"none\", d=5, norm = 'l2', ood_score = None):\n",
        "        self.ood_score = ood_score\n",
        "        self.initial_embed(reduce, d)\n",
        "        self.initial_norm(norm)\n",
        "        self.gamma_in = self.gamma_residual\n",
        "        print(self.__dict__)\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "\n",
        "    def linear(self, X, y, *args, **kwargs):\n",
        "        return {\"no\":y, \"linear\": self.linear_reranking(X, y, range(len(y)))}\n",
        "    def linear_reranking(self, X, y = None, index = None):\n",
        "        self.linear_reg = LinearRegression()\n",
        "        X_in = X[index]\n",
        "        y_in = y[index]\n",
        "        self.linear_reg.fit(X_in, y_in)\n",
        "        return self.linear_reg.predict(X)\n",
        "\n",
        "    def reranking(self, X, y = None, percent = 0.6, alpha = 1e-5):\n",
        "        if y is None:\n",
        "            y = self.ood_score(X).reshape(-1,1)\n",
        "        gammas = self.compute_gamma(X, y, alpha)\n",
        "        index_in = np.argsort(gammas)[:int(len(X) * percent)]\n",
        "        return self.linear_reranking(X, y, index_in)\n",
        "\n",
        "    def reranking_list(self, X, y = None, percent = None, alpha = 1e-5):\n",
        "        if y is None:\n",
        "            y = self.ood_score(X).reshape(-1,1)\n",
        "        if not isinstance(percent, list):\n",
        "            pass\n",
        "        gammas = self.compute_gamma(X, y, alpha)\n",
        "        results = {}\n",
        "        for a_percent in percent:\n",
        "            index_in = np.argsort(gammas)[:int(len(X) * a_percent)]\n",
        "            self.linear_reranking(X, y, index_in)\n",
        "            results[a_percent] = self.linear_reg.predict(X)\n",
        "        return results\n",
        "\n",
        "    def compute_gamma(self, X, y = None, alpha = 1e-5):\n",
        "        if y is None:\n",
        "            y = self.ood_score(X).reshape(-1,1)\n",
        "        normed_X = self.norm(X)\n",
        "        X = self.embed(normed_X)\n",
        "        H = np.dot(np.dot(X, np.linalg.pinv(np.dot(X.T, X))), X.T)\n",
        "        X_hat = np.eye(H.shape[0]) - H\n",
        "        y_hat = np.dot(X_hat, y)\n",
        "        return self.gamma_in(X_hat, y_hat, alpha)\n",
        "\n",
        "\n",
        "    def gamma_residual(self, X_hat, y_hat, alpha):\n",
        "\n",
        "        self.elasticnet = ElasticNet(alpha=alpha, l1_ratio=1.0, fit_intercept=True,\n",
        "                                #  normalize=True,\n",
        "                                warm_start=True, selection='cyclic')\n",
        "        X_hat = self.scaler.fit_transform(X_hat)\n",
        "        self.elasticnet.fit(X_hat, y_hat)\n",
        "        print(\"self.elasticnet.coef_:\", self.elasticnet.coef_.shape)\n",
        "        if self.elasticnet.coef_.ndim == 2:\n",
        "            #[n_target, n_feature]\n",
        "            coefs = self.elasticnet.coef_.T\n",
        "            #[n_feature, n_target] = [n_sample, n_target]\n",
        "            coefs = np.sum(np.abs(coefs), axis=1)\n",
        "            return coefs\n",
        "        elif self.elasticnet.coef_.ndim == 1:\n",
        "            #[n_feature] = [n_sample]\n",
        "            coefs = np.abs(self.elasticnet.coef_)\n",
        "            return coefs\n",
        "        else:\n",
        "            raise RuntimeError\n",
        "\n",
        "    def initial_embed(self, reduce, d):\n",
        "        reduce = reduce.lower()\n",
        "        assert reduce in ['isomap', 'ltsa', 'mds', 'lle', 'se', 'pca', 'none']\n",
        "        if reduce == 'isomap':\n",
        "            from sklearn.manifold import Isomap\n",
        "            embed = Isomap(n_components=d)\n",
        "        elif reduce == 'ltsa':\n",
        "            from sklearn.manifold import LocallyLinearEmbedding\n",
        "            embed = LocallyLinearEmbedding(n_components=d,\n",
        "                                           n_neighbors=5, method='ltsa')\n",
        "        elif reduce == 'mds':\n",
        "            from sklearn.manifold import MDS\n",
        "            embed = MDS(n_components=d, metric=False)\n",
        "        elif reduce == 'lle':\n",
        "            from sklearn.manifold import LocallyLinearEmbedding\n",
        "            embed = LocallyLinearEmbedding(n_components=d, n_neighbors=5,eigen_solver='dense')\n",
        "        elif reduce == 'se':\n",
        "            from sklearn.manifold import SpectralEmbedding\n",
        "            embed = SpectralEmbedding(n_components=d)\n",
        "        elif reduce == 'pca':\n",
        "            from sklearn.decomposition import PCA\n",
        "            embed = PCA(n_components=d)\n",
        "        if reduce == 'none':\n",
        "            self.embed = lambda x: x\n",
        "        else:\n",
        "            self.embed = lambda x: embed.fit_transform(x)\n",
        "\n",
        "    def initial_norm(self, norm):\n",
        "        norm = norm.lower()\n",
        "        assert norm in ['l2', 'none']\n",
        "        if norm == 'l2':\n",
        "            self.norm = lambda x: normalize(x)\n",
        "        else:\n",
        "            self.norm = lambda x: x\n",
        "\n",
        "rtl_ood = RTL_OOD()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHheTsGBUQ2m",
        "outputId": "2bd8c297-68ba-4aa6-8f7e-13694d91e767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ood_score': None, 'embed': <function RTL_OOD.initial_embed.<locals>.<lambda> at 0x7e6d654b32e0>, 'norm': <function RTL_OOD.initial_norm.<locals>.<lambda> at 0x7e6d74c2dd00>, 'gamma_in': <bound method RTL_OOD.gamma_residual of <__main__.RTL_OOD object at 0x7e6d747462d0>>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils"
      ],
      "metadata": {
        "id": "OH3y28JOHGtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/MQ-solutions/ood_practical/RTL/CIFAR\n",
        "!ls ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7ZlwbHyHKFB",
        "outputId": "f084f1dc-66f1-44b6-f50f-b29452123d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/19rDR7CIzlqpEM2y_t3vRDkf0-aHH8tdE/ood_practical/RTL/CIFAR\n",
            "CIFAR  simul  utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.display_results import show_performance, get_measures, print_measures, print_measures_with_std"
      ],
      "metadata": {
        "id": "SdBkqWZIHFy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fit PyOD"
      ],
      "metadata": {
        "id": "O6K7qBCJz1fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "from pyod.utils.data import evaluate_print\n",
        "contamination = 0.001\n",
        "\n",
        "clf = AutoEncoder(epoch_num=30, contamination=contamination)\n",
        "clf.fit(train_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k33y012qd1or",
        "outputId": "a3a97973-4a8f-49c5-a460-56a36099cf0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 30/30 [03:13<00:00,  6.46s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the prediction labels and outlier scores of the training data\n",
        "y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
        "y_train_scores = clf.decision_scores_  # raw outlier scores"
      ],
      "metadata": {
        "id": "TXxkDzklrSEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the prediction on the test data\n",
        "in_pred = clf.predict(in_features)  # outlier labels (0 or 1)\n",
        "in_score = clf.decision_function(in_features)  # outlier scores\n",
        "\n",
        "# count 1 and 0 in y_test_pred\n",
        "np.unique(in_pred, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO_a0Uuy4ZG6",
        "outputId": "007fcdda-7825-4309-d428-446657ad1cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([9992,    8]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_pred.shape, in_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By2xz0_1-jys",
        "outputId": "604f8ea8-8d2e-46c0-aa6e-1dca642accc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# texture\n",
        "# get the prediction on the test data\n",
        "y_texture_pred = clf.predict(texture_features)  # outlier labels (0 or 1)\n",
        "y_texture_scores = clf.decision_function(texture_features)  # outlier scores\n",
        "\n",
        "# count 1 and 0 in y_texture_pred\n",
        "np.unique(y_texture_pred, return_counts=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZEOPq_84hpd",
        "outputId": "511b0f6d-c160-4541-96ea-c7a52bdd7feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1]), array([5640]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_texture_pred.shape, y_texture_scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgJz1waYEujK",
        "outputId": "2c55ac02-ff72-4b5e-c5d2-0796426a3a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5640,), (5640,))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ood_num_examples = len(test_features) // 5\n",
        "expected_ap = ood_num_examples / (ood_num_examples + len(test_features))"
      ],
      "metadata": {
        "id": "sEwwcDUcAOpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_score  = in_scores\n",
        "in_feature = test_features"
      ],
      "metadata": {
        "id": "DFMriL7tFzts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ood_scores(features, in_dist=False):\n",
        "    _score = []\n",
        "    _feature = []\n",
        "    _right_score = []\n",
        "    _wrong_score = []\n",
        "\n",
        "    if not in_dist:\n",
        "        features = features[:ood_num_examples]\n",
        "\n",
        "    preds = clf.predict(features)\n",
        "    _score = clf.decision_function(features)\n",
        "    _feature = features\n",
        "\n",
        "    if in_dist:\n",
        "        right_indices = preds == 0\n",
        "        wrong_indices = np.invert(right_indices)\n",
        "        _right_score.append(_score[-1][right_indices])\n",
        "        _wrong_score.append(_score[-1][wrong_indices])\n",
        "\n",
        "        return _score, _right_score, _wrong_score, _feature\n",
        "    return _score, _feature"
      ],
      "metadata": {
        "id": "-HhquyDP9usw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percent = ['no', 'linear']\n",
        "num_to_avg = 10\n",
        "alpha = 1e-5\n",
        "\n",
        "def get_and_print_results(ood_loader):\n",
        "  aurocs, auprs, fprs = {i:[] for i in percent}, {i:[] for i in percent}, {i:[] for i in percent}\n",
        "\n",
        "  for _ in range(num_to_avg):\n",
        "    out_score, out_feature = get_ood_scores(ood_loader)\n",
        "\n",
        "    num_in = len(in_score)\n",
        "    print(\"num_in\",num_in)\n",
        "    in_and_out_score = np.concatenate((in_score, out_score))\n",
        "    in_and_out_feature = np.concatenate((in_feature, out_feature))\n",
        "    score_cal = rtl_ood.linear(in_and_out_feature, in_and_out_score, percent, alpha)\n",
        "    print('successful calculate linear calibration!')\n",
        "\n",
        "    for a_percent in percent:\n",
        "      a_score_cal = score_cal[a_percent]\n",
        "      in_score_changed, out_score = a_score_cal[:num_in], a_score_cal[num_in:]\n",
        "      measures = get_measures(-in_score_changed, -out_score)\n",
        "\n",
        "      aurocs[a_percent].append(measures[0]); auprs[a_percent].append(measures[1]); fprs[a_percent].append(measures[2])\n",
        "\n",
        "  for a_percent in percent:\n",
        "    auroc = np.mean(aurocs[a_percent])\n",
        "    aupr = np.mean(auprs[a_percent])\n",
        "    fpr = np.mean(fprs[a_percent])\n",
        "\n",
        "    print_measures(auroc, aupr, fpr, a_percent)\n"
      ],
      "metadata": {
        "id": "wUJ4PRnn9yTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluation"
      ],
      "metadata": {
        "id": "s0QIsuxoD2dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Texture\n",
        "get_and_print_results(texture_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72_nv8hb9y1r",
        "outputId": "0c2839cc-335e-48a6-ac2d-232bad9ad156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "\t\t\t\tno\n",
            "  FPR95 AUROC AUPR\n",
            "& 0.00 & 100.00 & 100.00\n",
            "\t\t\t\tlinear\n",
            "  FPR95 AUROC AUPR\n",
            "& 0.00 & 100.00 & 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Places365\n",
        "get_and_print_results(places365_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AohG3QG-IXIX",
        "outputId": "3cc4020d-d7ac-4852-96f4-6e9f461a04bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "\t\t\t\tno\n",
            "  FPR95 AUROC AUPR\n",
            "& 0.00 & 100.00 & 100.00\n",
            "\t\t\t\tlinear\n",
            "  FPR95 AUROC AUPR\n",
            "& 0.00 & 100.00 & 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSUN-C\n",
        "get_and_print_results(lsun_c_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZC_sLXXIh51",
        "outputId": "ce963d42-90fc-4b68-9a8f-ed1dab9afac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "\t\t\t\tno\n",
            "  FPR95 AUROC AUPR\n",
            "& 37.55 & 91.61 & 98.01\n",
            "\t\t\t\tlinear\n",
            "  FPR95 AUROC AUPR\n",
            "& 33.50 & 93.19 & 98.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSUN-R\n",
        "get_and_print_results(lsun_r_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sUs5ksfIsCW",
        "outputId": "596a6d67-02df-4449-e60c-476a788b1dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "\t\t\t\tno\n",
            "  FPR95 AUROC AUPR\n",
            "& 80.00 & 80.58 & 95.65\n",
            "\t\t\t\tlinear\n",
            "  FPR95 AUROC AUPR\n",
            "& 76.10 & 82.71 & 96.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ISUN\n",
        "get_and_print_results(isun_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDW81VV_Ix8P",
        "outputId": "7c50b43a-1712-47b0-916f-e26e2128062f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "num_in 10000\n",
            "successful calculate linear calibration!\n",
            "\t\t\t\tno\n",
            "  FPR95 AUROC AUPR\n",
            "& 75.20 & 82.20 & 96.01\n",
            "\t\t\t\tlinear\n",
            "  FPR95 AUROC AUPR\n",
            "& 71.70 & 84.33 & 96.60\n"
          ]
        }
      ]
    }
  ]
}